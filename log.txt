FOLD 0
Let's use 10 GPUs!
####### total m2p2 hyper-parameters  924577
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(73, 32, kernel_size=(28,), stride=(3,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
70992
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(512, 32, kernel_size=(30,), stride=(5,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
497104
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(200, 32, kernel_size=(34,), stride=(9,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
223184
BiAttnModel(
  (trans_a_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_a_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (fc1): Linear(in_features=64, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=1, bias=False)
)
73920
TriAttnModel(
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=64, out_features=32, bias=True)
  (fc3): Linear(in_features=64, out_features=32, bias=True)
)
6240
PersModel(
  (fc1): Linear(in_features=162, out_features=324, bias=True)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc2): Linear(in_features=324, out_features=1, bias=True)
  (sigm): Sigmoid()
)
53137
[SAVE MODEL] eval pers loss: 0.02500	mini pers loss: 100000.00000	eval acc: 0.1321	max_acc: 0.0000
Epoch: 01/40 | Time: 0m 15s
	Train persuasion loss:0.02450	Train MAE Loss:0.12808
	Eval persuasion loss:0.02500	Eval MAE Loss:0.13209
[SAVE MODEL] eval pers loss: 0.02110	mini pers loss: 0.02500	eval acc: 0.1159	max_acc: 0.1321
Epoch: 02/40 | Time: 0m 9s
	Train persuasion loss:0.02025	Train MAE Loss:0.11619
	Eval persuasion loss:0.02110	Eval MAE Loss:0.11593
Epoch: 03/40 | Time: 0m 9s
	Train persuasion loss:0.01814	Train MAE Loss:0.10683
	Eval persuasion loss:0.02144	Eval MAE Loss:0.11482
[SAVE MODEL] eval pers loss: 0.02067	mini pers loss: 0.02110	eval acc: 0.1157	max_acc: 0.1159
Epoch: 04/40 | Time: 0m 9s
	Train persuasion loss:0.01611	Train MAE Loss:0.10077
	Eval persuasion loss:0.02067	Eval MAE Loss:0.11570
Epoch: 05/40 | Time: 0m 9s
	Train persuasion loss:0.01657	Train MAE Loss:0.09879
	Eval persuasion loss:0.02976	Eval MAE Loss:0.13869
Epoch: 06/40 | Time: 0m 9s
	Train persuasion loss:0.01508	Train MAE Loss:0.09565
	Eval persuasion loss:0.02371	Eval MAE Loss:0.12484
Epoch: 07/40 | Time: 0m 10s
	Train persuasion loss:0.01463	Train MAE Loss:0.09398
	Eval persuasion loss:0.02557	Eval MAE Loss:0.12695
Epoch: 08/40 | Time: 0m 10s
	Train persuasion loss:0.01411	Train MAE Loss:0.09397
	Eval persuasion loss:0.02372	Eval MAE Loss:0.12741
Epoch: 09/40 | Time: 0m 9s
	Train persuasion loss:0.01199	Train MAE Loss:0.08389
	Eval persuasion loss:0.02677	Eval MAE Loss:0.13678
Epoch: 10/40 | Time: 0m 10s
	Train persuasion loss:0.01236	Train MAE Loss:0.08614
	Eval persuasion loss:0.02182	Eval MAE Loss:0.12719
Epoch: 11/40 | Time: 0m 9s
	Train persuasion loss:0.01104	Train MAE Loss:0.08075
	Eval persuasion loss:0.02588	Eval MAE Loss:0.13444
Epoch: 12/40 | Time: 0m 10s
	Train persuasion loss:0.01009	Train MAE Loss:0.07723
	Eval persuasion loss:0.02964	Eval MAE Loss:0.14685
Epoch: 13/40 | Time: 0m 9s
	Train persuasion loss:0.01010	Train MAE Loss:0.07771
	Eval persuasion loss:0.02787	Eval MAE Loss:0.14050
Epoch: 14/40 | Time: 0m 9s
	Train persuasion loss:0.00976	Train MAE Loss:0.07564
	Eval persuasion loss:0.02817	Eval MAE Loss:0.14088
Epoch: 15/40 | Time: 0m 9s
	Train persuasion loss:0.00934	Train MAE Loss:0.07540
	Eval persuasion loss:0.02769	Eval MAE Loss:0.14138
Epoch: 16/40 | Time: 0m 9s
	Train persuasion loss:0.00874	Train MAE Loss:0.07299
	Eval persuasion loss:0.02635	Eval MAE Loss:0.14025
Epoch: 17/40 | Time: 0m 10s
	Train persuasion loss:0.00875	Train MAE Loss:0.07308
	Eval persuasion loss:0.02668	Eval MAE Loss:0.13840
Epoch: 18/40 | Time: 0m 9s
	Train persuasion loss:0.00821	Train MAE Loss:0.07043
	Eval persuasion loss:0.02746	Eval MAE Loss:0.14139
Epoch: 19/40 | Time: 0m 9s
	Train persuasion loss:0.00846	Train MAE Loss:0.07105
	Eval persuasion loss:0.02906	Eval MAE Loss:0.14719
Epoch: 20/40 | Time: 0m 9s
	Train persuasion loss:0.00766	Train MAE Loss:0.06834
	Eval persuasion loss:0.02935	Eval MAE Loss:0.14620
Epoch: 21/40 | Time: 0m 9s
	Train persuasion loss:0.00753	Train MAE Loss:0.06759
	Eval persuasion loss:0.02904	Eval MAE Loss:0.14643
Epoch: 22/40 | Time: 0m 9s
	Train persuasion loss:0.00792	Train MAE Loss:0.06945
	Eval persuasion loss:0.02885	Eval MAE Loss:0.14599
Epoch: 23/40 | Time: 0m 9s
	Train persuasion loss:0.00746	Train MAE Loss:0.06810
	Eval persuasion loss:0.02925	Eval MAE Loss:0.14543
Epoch: 24/40 | Time: 0m 9s
	Train persuasion loss:0.00724	Train MAE Loss:0.06663
	Eval persuasion loss:0.02913	Eval MAE Loss:0.14496
Epoch: 25/40 | Time: 0m 9s
	Train persuasion loss:0.00755	Train MAE Loss:0.06829
	Eval persuasion loss:0.02962	Eval MAE Loss:0.14619
Epoch: 26/40 | Time: 0m 9s
	Train persuasion loss:0.00719	Train MAE Loss:0.06609
	Eval persuasion loss:0.02924	Eval MAE Loss:0.14590
Epoch: 27/40 | Time: 0m 8s
	Train persuasion loss:0.00715	Train MAE Loss:0.06600
	Eval persuasion loss:0.02927	Eval MAE Loss:0.14584
Epoch: 28/40 | Time: 0m 9s
	Train persuasion loss:0.00714	Train MAE Loss:0.06651
	Eval persuasion loss:0.02939	Eval MAE Loss:0.14645
Epoch: 29/40 | Time: 0m 9s
	Train persuasion loss:0.00746	Train MAE Loss:0.06726
	Eval persuasion loss:0.02991	Eval MAE Loss:0.14764
Epoch: 30/40 | Time: 0m 10s
	Train persuasion loss:0.00689	Train MAE Loss:0.06471
	Eval persuasion loss:0.02937	Eval MAE Loss:0.14617
Epoch: 31/40 | Time: 0m 9s
	Train persuasion loss:0.00713	Train MAE Loss:0.06731
	Eval persuasion loss:0.02931	Eval MAE Loss:0.14618
Epoch: 32/40 | Time: 0m 9s
	Train persuasion loss:0.00680	Train MAE Loss:0.06448
	Eval persuasion loss:0.02938	Eval MAE Loss:0.14635
Epoch: 33/40 | Time: 0m 10s
	Train persuasion loss:0.00695	Train MAE Loss:0.06512
	Eval persuasion loss:0.02944	Eval MAE Loss:0.14659
Epoch: 34/40 | Time: 0m 10s
	Train persuasion loss:0.00702	Train MAE Loss:0.06556
	Eval persuasion loss:0.02949	Eval MAE Loss:0.14675
Epoch: 35/40 | Time: 0m 10s
	Train persuasion loss:0.00630	Train MAE Loss:0.06245
	Eval persuasion loss:0.02944	Eval MAE Loss:0.14668
Epoch: 36/40 | Time: 0m 10s
	Train persuasion loss:0.00702	Train MAE Loss:0.06539
	Eval persuasion loss:0.02961	Eval MAE Loss:0.14705
Epoch: 37/40 | Time: 0m 10s
	Train persuasion loss:0.00719	Train MAE Loss:0.06606
	Eval persuasion loss:0.02945	Eval MAE Loss:0.14674
Epoch: 38/40 | Time: 0m 9s
	Train persuasion loss:0.00725	Train MAE Loss:0.06622
	Eval persuasion loss:0.02937	Eval MAE Loss:0.14647
Epoch: 39/40 | Time: 0m 10s
	Train persuasion loss:0.00650	Train MAE Loss:0.06360
	Eval persuasion loss:0.02959	Eval MAE Loss:0.14703
Epoch: 40/40 | Time: 0m 10s
	Train persuasion loss:0.00671	Train MAE Loss:0.06435
	Eval persuasion loss:0.02943	Eval MAE Loss:0.14671
FOLD 0
Let's use 10 GPUs!
Test persuasion loss:0.01361	Test MAE Loss:0.10526
MSE: 0.014
FOLD 1
Let's use 10 GPUs!
####### total m2p2 hyper-parameters  924577
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(73, 32, kernel_size=(28,), stride=(3,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
70992
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(512, 32, kernel_size=(30,), stride=(5,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
497104
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(200, 32, kernel_size=(34,), stride=(9,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
223184
BiAttnModel(
  (trans_a_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_a_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (fc1): Linear(in_features=64, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=1, bias=False)
)
73920
TriAttnModel(
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=64, out_features=32, bias=True)
  (fc3): Linear(in_features=64, out_features=32, bias=True)
)
6240
PersModel(
  (fc1): Linear(in_features=162, out_features=324, bias=True)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc2): Linear(in_features=324, out_features=1, bias=True)
  (sigm): Sigmoid()
)
53137
[SAVE MODEL] eval pers loss: 0.02129	mini pers loss: 100000.00000	eval acc: 0.1189	max_acc: 0.0000
Epoch: 01/40 | Time: 0m 10s
	Train persuasion loss:0.02470	Train MAE Loss:0.13102
	Eval persuasion loss:0.02129	Eval MAE Loss:0.11894
Epoch: 02/40 | Time: 0m 10s
	Train persuasion loss:0.02177	Train MAE Loss:0.12233
	Eval persuasion loss:0.02251	Eval MAE Loss:0.12173
Epoch: 03/40 | Time: 0m 10s
	Train persuasion loss:0.01892	Train MAE Loss:0.10983
	Eval persuasion loss:0.02638	Eval MAE Loss:0.12574
Epoch: 04/40 | Time: 0m 9s
	Train persuasion loss:0.01816	Train MAE Loss:0.10669
	Eval persuasion loss:0.02733	Eval MAE Loss:0.12203
Epoch: 05/40 | Time: 0m 9s
	Train persuasion loss:0.01557	Train MAE Loss:0.09764
	Eval persuasion loss:0.02941	Eval MAE Loss:0.13132
Epoch: 06/40 | Time: 0m 9s
	Train persuasion loss:0.01563	Train MAE Loss:0.09696
	Eval persuasion loss:0.03077	Eval MAE Loss:0.13484
Epoch: 07/40 | Time: 0m 9s
	Train persuasion loss:0.01611	Train MAE Loss:0.09910
	Eval persuasion loss:0.03407	Eval MAE Loss:0.14222
Epoch: 08/40 | Time: 0m 10s
	Train persuasion loss:0.01562	Train MAE Loss:0.09689
	Eval persuasion loss:0.02947	Eval MAE Loss:0.13447
Epoch: 09/40 | Time: 0m 10s
	Train persuasion loss:0.01443	Train MAE Loss:0.09389
	Eval persuasion loss:0.03310	Eval MAE Loss:0.14319
Epoch: 10/40 | Time: 0m 10s
	Train persuasion loss:0.01325	Train MAE Loss:0.08850
	Eval persuasion loss:0.03554	Eval MAE Loss:0.15537
Epoch: 11/40 | Time: 0m 10s
	Train persuasion loss:0.01195	Train MAE Loss:0.08443
	Eval persuasion loss:0.03423	Eval MAE Loss:0.13858
Epoch: 12/40 | Time: 0m 10s
	Train persuasion loss:0.01192	Train MAE Loss:0.08401
	Eval persuasion loss:0.03596	Eval MAE Loss:0.14917
Epoch: 13/40 | Time: 0m 10s
	Train persuasion loss:0.01136	Train MAE Loss:0.08189
	Eval persuasion loss:0.03538	Eval MAE Loss:0.14623
Epoch: 14/40 | Time: 0m 10s
	Train persuasion loss:0.01088	Train MAE Loss:0.08065
	Eval persuasion loss:0.03511	Eval MAE Loss:0.14570
Epoch: 15/40 | Time: 0m 10s
	Train persuasion loss:0.01054	Train MAE Loss:0.07830
	Eval persuasion loss:0.03590	Eval MAE Loss:0.14786
Epoch: 16/40 | Time: 0m 9s
	Train persuasion loss:0.01007	Train MAE Loss:0.07767
	Eval persuasion loss:0.03635	Eval MAE Loss:0.15056
Epoch: 17/40 | Time: 0m 10s
	Train persuasion loss:0.00968	Train MAE Loss:0.07692
	Eval persuasion loss:0.03581	Eval MAE Loss:0.14563
Epoch: 18/40 | Time: 0m 10s
	Train persuasion loss:0.00958	Train MAE Loss:0.07537
	Eval persuasion loss:0.03548	Eval MAE Loss:0.14634
Epoch: 19/40 | Time: 0m 10s
	Train persuasion loss:0.00871	Train MAE Loss:0.07274
	Eval persuasion loss:0.03570	Eval MAE Loss:0.14661
Epoch: 20/40 | Time: 0m 9s
	Train persuasion loss:0.00874	Train MAE Loss:0.07288
	Eval persuasion loss:0.03780	Eval MAE Loss:0.15572
Epoch: 21/40 | Time: 0m 10s
	Train persuasion loss:0.00846	Train MAE Loss:0.07155
	Eval persuasion loss:0.03690	Eval MAE Loss:0.15258
Epoch: 22/40 | Time: 0m 10s
	Train persuasion loss:0.00857	Train MAE Loss:0.07092
	Eval persuasion loss:0.03591	Eval MAE Loss:0.14785
Epoch: 23/40 | Time: 0m 10s
	Train persuasion loss:0.00879	Train MAE Loss:0.07324
	Eval persuasion loss:0.03640	Eval MAE Loss:0.15049
Epoch: 24/40 | Time: 0m 9s
	Train persuasion loss:0.00795	Train MAE Loss:0.06837
	Eval persuasion loss:0.03661	Eval MAE Loss:0.15023
Epoch: 25/40 | Time: 0m 10s
	Train persuasion loss:0.00834	Train MAE Loss:0.07146
	Eval persuasion loss:0.03647	Eval MAE Loss:0.15030
Epoch: 26/40 | Time: 0m 10s
	Train persuasion loss:0.00820	Train MAE Loss:0.07070
	Eval persuasion loss:0.03658	Eval MAE Loss:0.15016
Epoch: 27/40 | Time: 0m 10s
	Train persuasion loss:0.00813	Train MAE Loss:0.06974
	Eval persuasion loss:0.03673	Eval MAE Loss:0.15064
Epoch: 28/40 | Time: 0m 10s
	Train persuasion loss:0.00814	Train MAE Loss:0.07085
	Eval persuasion loss:0.03744	Eval MAE Loss:0.15172
Epoch: 29/40 | Time: 0m 9s
	Train persuasion loss:0.00809	Train MAE Loss:0.07040
	Eval persuasion loss:0.03717	Eval MAE Loss:0.14937
Epoch: 30/40 | Time: 0m 10s
	Train persuasion loss:0.00836	Train MAE Loss:0.07142
	Eval persuasion loss:0.03736	Eval MAE Loss:0.15147
Epoch: 31/40 | Time: 0m 10s
	Train persuasion loss:0.00775	Train MAE Loss:0.06819
	Eval persuasion loss:0.03728	Eval MAE Loss:0.15111
Epoch: 32/40 | Time: 0m 10s
	Train persuasion loss:0.00773	Train MAE Loss:0.06824
	Eval persuasion loss:0.03733	Eval MAE Loss:0.15131
Epoch: 33/40 | Time: 0m 10s
	Train persuasion loss:0.00797	Train MAE Loss:0.06980
	Eval persuasion loss:0.03734	Eval MAE Loss:0.15135
Epoch: 34/40 | Time: 0m 10s
	Train persuasion loss:0.00766	Train MAE Loss:0.06814
	Eval persuasion loss:0.03733	Eval MAE Loss:0.15125
Epoch: 35/40 | Time: 0m 10s
	Train persuasion loss:0.00816	Train MAE Loss:0.07031
	Eval persuasion loss:0.03730	Eval MAE Loss:0.15125
Epoch: 36/40 | Time: 0m 10s
	Train persuasion loss:0.00845	Train MAE Loss:0.06992
	Eval persuasion loss:0.03740	Eval MAE Loss:0.15164
Epoch: 37/40 | Time: 0m 10s
	Train persuasion loss:0.00814	Train MAE Loss:0.06996
	Eval persuasion loss:0.03753	Eval MAE Loss:0.15194
Epoch: 38/40 | Time: 0m 10s
	Train persuasion loss:0.00835	Train MAE Loss:0.06967
	Eval persuasion loss:0.03756	Eval MAE Loss:0.15182
Epoch: 39/40 | Time: 0m 10s
	Train persuasion loss:0.00805	Train MAE Loss:0.07049
	Eval persuasion loss:0.03754	Eval MAE Loss:0.15177
Epoch: 40/40 | Time: 0m 10s
	Train persuasion loss:0.00790	Train MAE Loss:0.06955
	Eval persuasion loss:0.03750	Eval MAE Loss:0.15177
FOLD 1
Let's use 10 GPUs!
Test persuasion loss:0.02108	Test MAE Loss:0.11905
MSE: 0.021
FOLD 2
Let's use 10 GPUs!
####### total m2p2 hyper-parameters  924577
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(73, 32, kernel_size=(28,), stride=(3,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
70992
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(512, 32, kernel_size=(30,), stride=(5,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
497104
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(200, 32, kernel_size=(34,), stride=(9,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
223184
BiAttnModel(
  (trans_a_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_a_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (fc1): Linear(in_features=64, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=1, bias=False)
)
73920
TriAttnModel(
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=64, out_features=32, bias=True)
  (fc3): Linear(in_features=64, out_features=32, bias=True)
)
6240
PersModel(
  (fc1): Linear(in_features=162, out_features=324, bias=True)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc2): Linear(in_features=324, out_features=1, bias=True)
  (sigm): Sigmoid()
)
53137
[SAVE MODEL] eval pers loss: 0.02435	mini pers loss: 100000.00000	eval acc: 0.1127	max_acc: 0.0000
Epoch: 01/40 | Time: 0m 10s
	Train persuasion loss:0.02419	Train MAE Loss:0.12892
	Eval persuasion loss:0.02435	Eval MAE Loss:0.11267
Epoch: 02/40 | Time: 0m 10s
	Train persuasion loss:0.02064	Train MAE Loss:0.11700
	Eval persuasion loss:0.02638	Eval MAE Loss:0.12293
Epoch: 03/40 | Time: 0m 9s
	Train persuasion loss:0.01898	Train MAE Loss:0.10820
	Eval persuasion loss:0.02642	Eval MAE Loss:0.11990
Epoch: 04/40 | Time: 0m 10s
	Train persuasion loss:0.01740	Train MAE Loss:0.10537
	Eval persuasion loss:0.03064	Eval MAE Loss:0.13757
Epoch: 05/40 | Time: 0m 10s
	Train persuasion loss:0.01675	Train MAE Loss:0.09994
	Eval persuasion loss:0.02610	Eval MAE Loss:0.12530
Epoch: 06/40 | Time: 0m 9s
	Train persuasion loss:0.01500	Train MAE Loss:0.09439
	Eval persuasion loss:0.02857	Eval MAE Loss:0.12771
Epoch: 07/40 | Time: 0m 10s
	Train persuasion loss:0.01458	Train MAE Loss:0.09273
	Eval persuasion loss:0.02858	Eval MAE Loss:0.13101
Epoch: 08/40 | Time: 0m 9s
	Train persuasion loss:0.01247	Train MAE Loss:0.08514
	Eval persuasion loss:0.03129	Eval MAE Loss:0.13326
Epoch: 09/40 | Time: 0m 9s
	Train persuasion loss:0.01214	Train MAE Loss:0.08388
	Eval persuasion loss:0.04098	Eval MAE Loss:0.15283
Epoch: 10/40 | Time: 0m 9s
	Train persuasion loss:0.01164	Train MAE Loss:0.08305
	Eval persuasion loss:0.03968	Eval MAE Loss:0.15170
Epoch: 11/40 | Time: 0m 9s
	Train persuasion loss:0.01007	Train MAE Loss:0.07692
	Eval persuasion loss:0.03910	Eval MAE Loss:0.15368
Epoch: 12/40 | Time: 0m 10s
	Train persuasion loss:0.00948	Train MAE Loss:0.07424
	Eval persuasion loss:0.04107	Eval MAE Loss:0.15976
Epoch: 13/40 | Time: 0m 9s
	Train persuasion loss:0.00947	Train MAE Loss:0.07387
	Eval persuasion loss:0.04104	Eval MAE Loss:0.15354
Epoch: 14/40 | Time: 0m 9s
	Train persuasion loss:0.00849	Train MAE Loss:0.06932
	Eval persuasion loss:0.04230	Eval MAE Loss:0.15539
Epoch: 15/40 | Time: 0m 9s
	Train persuasion loss:0.00838	Train MAE Loss:0.06992
	Eval persuasion loss:0.04225	Eval MAE Loss:0.15600
Epoch: 16/40 | Time: 0m 9s
	Train persuasion loss:0.00777	Train MAE Loss:0.06698
	Eval persuasion loss:0.04382	Eval MAE Loss:0.16100
Epoch: 17/40 | Time: 0m 9s
	Train persuasion loss:0.00791	Train MAE Loss:0.06581
	Eval persuasion loss:0.04306	Eval MAE Loss:0.15964
Epoch: 18/40 | Time: 0m 9s
	Train persuasion loss:0.00772	Train MAE Loss:0.06635
	Eval persuasion loss:0.04531	Eval MAE Loss:0.16307
Epoch: 19/40 | Time: 0m 9s
	Train persuasion loss:0.00745	Train MAE Loss:0.06634
	Eval persuasion loss:0.04635	Eval MAE Loss:0.16466
Epoch: 20/40 | Time: 0m 9s
	Train persuasion loss:0.00719	Train MAE Loss:0.06433
	Eval persuasion loss:0.04589	Eval MAE Loss:0.16448
Epoch: 21/40 | Time: 0m 9s
	Train persuasion loss:0.00739	Train MAE Loss:0.06450
	Eval persuasion loss:0.04728	Eval MAE Loss:0.16695
Epoch: 22/40 | Time: 0m 9s
	Train persuasion loss:0.00653	Train MAE Loss:0.06137
	Eval persuasion loss:0.04745	Eval MAE Loss:0.16734
Epoch: 23/40 | Time: 0m 10s
	Train persuasion loss:0.00655	Train MAE Loss:0.06186
	Eval persuasion loss:0.04707	Eval MAE Loss:0.16680
Epoch: 24/40 | Time: 0m 9s
	Train persuasion loss:0.00639	Train MAE Loss:0.06011
	Eval persuasion loss:0.04689	Eval MAE Loss:0.16666
Epoch: 25/40 | Time: 0m 9s
	Train persuasion loss:0.00615	Train MAE Loss:0.05905
	Eval persuasion loss:0.04638	Eval MAE Loss:0.16555
Epoch: 26/40 | Time: 0m 9s
	Train persuasion loss:0.00688	Train MAE Loss:0.06191
	Eval persuasion loss:0.04655	Eval MAE Loss:0.16589
Epoch: 27/40 | Time: 0m 9s
	Train persuasion loss:0.00648	Train MAE Loss:0.06051
	Eval persuasion loss:0.04717	Eval MAE Loss:0.16697
Epoch: 28/40 | Time: 0m 10s
	Train persuasion loss:0.00660	Train MAE Loss:0.06249
	Eval persuasion loss:0.04774	Eval MAE Loss:0.16796
Epoch: 29/40 | Time: 0m 9s
	Train persuasion loss:0.00656	Train MAE Loss:0.06191
	Eval persuasion loss:0.04817	Eval MAE Loss:0.16887
Epoch: 30/40 | Time: 0m 10s
	Train persuasion loss:0.00614	Train MAE Loss:0.05994
	Eval persuasion loss:0.04837	Eval MAE Loss:0.16934
Epoch: 31/40 | Time: 0m 9s
	Train persuasion loss:0.00627	Train MAE Loss:0.06066
	Eval persuasion loss:0.04833	Eval MAE Loss:0.16922
Epoch: 32/40 | Time: 0m 10s
	Train persuasion loss:0.00593	Train MAE Loss:0.06034
	Eval persuasion loss:0.04832	Eval MAE Loss:0.16929
Epoch: 33/40 | Time: 0m 9s
	Train persuasion loss:0.00593	Train MAE Loss:0.05956
	Eval persuasion loss:0.04832	Eval MAE Loss:0.16941
Epoch: 34/40 | Time: 0m 9s
	Train persuasion loss:0.00643	Train MAE Loss:0.06072
	Eval persuasion loss:0.04840	Eval MAE Loss:0.16942
Epoch: 35/40 | Time: 0m 10s
	Train persuasion loss:0.00641	Train MAE Loss:0.06105
	Eval persuasion loss:0.04840	Eval MAE Loss:0.16935
Epoch: 36/40 | Time: 0m 10s
	Train persuasion loss:0.00629	Train MAE Loss:0.06058
	Eval persuasion loss:0.04839	Eval MAE Loss:0.16918
Epoch: 37/40 | Time: 0m 10s
	Train persuasion loss:0.00573	Train MAE Loss:0.05724
	Eval persuasion loss:0.04834	Eval MAE Loss:0.16891
Epoch: 38/40 | Time: 0m 9s
	Train persuasion loss:0.00604	Train MAE Loss:0.06024
	Eval persuasion loss:0.04832	Eval MAE Loss:0.16890
Epoch: 39/40 | Time: 0m 9s
	Train persuasion loss:0.00595	Train MAE Loss:0.05937
	Eval persuasion loss:0.04821	Eval MAE Loss:0.16873
Epoch: 40/40 | Time: 0m 9s
	Train persuasion loss:0.00610	Train MAE Loss:0.05937
	Eval persuasion loss:0.04823	Eval MAE Loss:0.16876
FOLD 2
Let's use 10 GPUs!
Test persuasion loss:0.02692	Test MAE Loss:0.12739
MSE: 0.027
FOLD 3
Let's use 10 GPUs!
####### total m2p2 hyper-parameters  924577
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(73, 32, kernel_size=(28,), stride=(3,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
70992
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(512, 32, kernel_size=(30,), stride=(5,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
497104
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(200, 32, kernel_size=(34,), stride=(9,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
223184
BiAttnModel(
  (trans_a_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_a_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (fc1): Linear(in_features=64, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=1, bias=False)
)
73920
TriAttnModel(
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=64, out_features=32, bias=True)
  (fc3): Linear(in_features=64, out_features=32, bias=True)
)
6240
PersModel(
  (fc1): Linear(in_features=162, out_features=324, bias=True)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc2): Linear(in_features=324, out_features=1, bias=True)
  (sigm): Sigmoid()
)
53137
[SAVE MODEL] eval pers loss: 0.03043	mini pers loss: 100000.00000	eval acc: 0.1554	max_acc: 0.0000
Epoch: 01/40 | Time: 0m 8s
	Train persuasion loss:0.02512	Train MAE Loss:0.13154
	Eval persuasion loss:0.03043	Eval MAE Loss:0.15543
Epoch: 02/40 | Time: 0m 8s
	Train persuasion loss:0.02000	Train MAE Loss:0.11466
	Eval persuasion loss:0.03116	Eval MAE Loss:0.14901
Epoch: 03/40 | Time: 0m 8s
	Train persuasion loss:0.01780	Train MAE Loss:0.10680
	Eval persuasion loss:0.03748	Eval MAE Loss:0.16389
Epoch: 04/40 | Time: 0m 8s
	Train persuasion loss:0.01779	Train MAE Loss:0.10480
	Eval persuasion loss:0.03283	Eval MAE Loss:0.14767
Epoch: 05/40 | Time: 0m 8s
	Train persuasion loss:0.01608	Train MAE Loss:0.09745
	Eval persuasion loss:0.03184	Eval MAE Loss:0.14976
Epoch: 06/40 | Time: 0m 8s
	Train persuasion loss:0.01487	Train MAE Loss:0.09465
	Eval persuasion loss:0.03155	Eval MAE Loss:0.14790
Epoch: 07/40 | Time: 0m 8s
	Train persuasion loss:0.01310	Train MAE Loss:0.08509
	Eval persuasion loss:0.03803	Eval MAE Loss:0.16308
Epoch: 08/40 | Time: 0m 8s
	Train persuasion loss:0.01306	Train MAE Loss:0.08741
	Eval persuasion loss:0.03692	Eval MAE Loss:0.15718
Epoch: 09/40 | Time: 0m 8s
	Train persuasion loss:0.01158	Train MAE Loss:0.08041
	Eval persuasion loss:0.03367	Eval MAE Loss:0.14683
Epoch: 10/40 | Time: 0m 8s
	Train persuasion loss:0.01031	Train MAE Loss:0.07612
	Eval persuasion loss:0.03434	Eval MAE Loss:0.14746
Epoch: 11/40 | Time: 0m 8s
	Train persuasion loss:0.01009	Train MAE Loss:0.07491
	Eval persuasion loss:0.03611	Eval MAE Loss:0.15248
Epoch: 12/40 | Time: 0m 8s
	Train persuasion loss:0.00896	Train MAE Loss:0.07112
	Eval persuasion loss:0.04152	Eval MAE Loss:0.16415
Epoch: 13/40 | Time: 0m 8s
	Train persuasion loss:0.00901	Train MAE Loss:0.07087
	Eval persuasion loss:0.04263	Eval MAE Loss:0.16684
Epoch: 14/40 | Time: 0m 8s
	Train persuasion loss:0.00820	Train MAE Loss:0.06775
	Eval persuasion loss:0.04269	Eval MAE Loss:0.16769
Epoch: 15/40 | Time: 0m 7s
	Train persuasion loss:0.00899	Train MAE Loss:0.06626
	Eval persuasion loss:0.04452	Eval MAE Loss:0.17190
Epoch: 16/40 | Time: 0m 8s
	Train persuasion loss:0.00823	Train MAE Loss:0.06764
	Eval persuasion loss:0.04361	Eval MAE Loss:0.17136
Epoch: 17/40 | Time: 0m 8s
	Train persuasion loss:0.00747	Train MAE Loss:0.06675
	Eval persuasion loss:0.04626	Eval MAE Loss:0.17628
Epoch: 18/40 | Time: 0m 8s
	Train persuasion loss:0.00735	Train MAE Loss:0.06500
	Eval persuasion loss:0.05023	Eval MAE Loss:0.18424
Epoch: 19/40 | Time: 0m 8s
	Train persuasion loss:0.00640	Train MAE Loss:0.06013
	Eval persuasion loss:0.05019	Eval MAE Loss:0.18431
Epoch: 20/40 | Time: 0m 8s
	Train persuasion loss:0.00712	Train MAE Loss:0.06256
	Eval persuasion loss:0.05364	Eval MAE Loss:0.18576
Epoch: 21/40 | Time: 0m 8s
	Train persuasion loss:0.00666	Train MAE Loss:0.06369
	Eval persuasion loss:0.05317	Eval MAE Loss:0.18665
Epoch: 22/40 | Time: 0m 8s
	Train persuasion loss:0.00646	Train MAE Loss:0.06140
	Eval persuasion loss:0.05308	Eval MAE Loss:0.18786
Epoch: 23/40 | Time: 0m 8s
	Train persuasion loss:0.00581	Train MAE Loss:0.05779
	Eval persuasion loss:0.05379	Eval MAE Loss:0.18935
Epoch: 24/40 | Time: 0m 8s
	Train persuasion loss:0.00637	Train MAE Loss:0.05995
	Eval persuasion loss:0.05356	Eval MAE Loss:0.18919
Epoch: 25/40 | Time: 0m 8s
	Train persuasion loss:0.00606	Train MAE Loss:0.06072
	Eval persuasion loss:0.05324	Eval MAE Loss:0.18904
Epoch: 26/40 | Time: 0m 8s
	Train persuasion loss:0.00631	Train MAE Loss:0.05947
	Eval persuasion loss:0.05365	Eval MAE Loss:0.18938
Epoch: 27/40 | Time: 0m 8s
	Train persuasion loss:0.00592	Train MAE Loss:0.05843
	Eval persuasion loss:0.05351	Eval MAE Loss:0.18961
Epoch: 28/40 | Time: 0m 8s
	Train persuasion loss:0.00612	Train MAE Loss:0.05827
	Eval persuasion loss:0.05358	Eval MAE Loss:0.18969
Epoch: 29/40 | Time: 0m 8s
	Train persuasion loss:0.00594	Train MAE Loss:0.05864
	Eval persuasion loss:0.05386	Eval MAE Loss:0.18955
Epoch: 30/40 | Time: 0m 9s
	Train persuasion loss:0.00590	Train MAE Loss:0.05778
	Eval persuasion loss:0.05373	Eval MAE Loss:0.18914
Epoch: 31/40 | Time: 0m 12s
	Train persuasion loss:0.00642	Train MAE Loss:0.06210
	Eval persuasion loss:0.05363	Eval MAE Loss:0.18942
Epoch: 32/40 | Time: 0m 13s
	Train persuasion loss:0.00607	Train MAE Loss:0.05868
	Eval persuasion loss:0.05365	Eval MAE Loss:0.18975
Epoch: 33/40 | Time: 0m 13s
	Train persuasion loss:0.00639	Train MAE Loss:0.06002
	Eval persuasion loss:0.05372	Eval MAE Loss:0.18964
Epoch: 34/40 | Time: 0m 13s
	Train persuasion loss:0.00602	Train MAE Loss:0.06017
	Eval persuasion loss:0.05391	Eval MAE Loss:0.18982
Epoch: 35/40 | Time: 0m 13s
	Train persuasion loss:0.00580	Train MAE Loss:0.05798
	Eval persuasion loss:0.05409	Eval MAE Loss:0.19026
Epoch: 36/40 | Time: 0m 13s
	Train persuasion loss:0.00607	Train MAE Loss:0.05922
	Eval persuasion loss:0.05406	Eval MAE Loss:0.19052
Epoch: 37/40 | Time: 0m 13s
	Train persuasion loss:0.00620	Train MAE Loss:0.05976
	Eval persuasion loss:0.05417	Eval MAE Loss:0.19058
Epoch: 38/40 | Time: 0m 13s
	Train persuasion loss:0.00559	Train MAE Loss:0.05734
	Eval persuasion loss:0.05435	Eval MAE Loss:0.19082
Epoch: 39/40 | Time: 0m 14s
	Train persuasion loss:0.00630	Train MAE Loss:0.05893
	Eval persuasion loss:0.05435	Eval MAE Loss:0.19092
Epoch: 40/40 | Time: 0m 13s
	Train persuasion loss:0.00579	Train MAE Loss:0.05749
	Eval persuasion loss:0.05424	Eval MAE Loss:0.19075
FOLD 3
Let's use 10 GPUs!
Test persuasion loss:0.01771	Test MAE Loss:0.09890
MSE: 0.018
FOLD 4
Let's use 10 GPUs!
####### total m2p2 hyper-parameters  924577
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(73, 32, kernel_size=(28,), stride=(3,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
70992
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(512, 32, kernel_size=(30,), stride=(5,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
497104
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(200, 32, kernel_size=(34,), stride=(9,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
223184
BiAttnModel(
  (trans_a_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_a_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (fc1): Linear(in_features=64, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=1, bias=False)
)
73920
TriAttnModel(
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=64, out_features=32, bias=True)
  (fc3): Linear(in_features=64, out_features=32, bias=True)
)
6240
PersModel(
  (fc1): Linear(in_features=162, out_features=324, bias=True)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc2): Linear(in_features=324, out_features=1, bias=True)
  (sigm): Sigmoid()
)
53137
[SAVE MODEL] eval pers loss: 0.02664	mini pers loss: 100000.00000	eval acc: 0.1338	max_acc: 0.0000
Epoch: 01/40 | Time: 0m 13s
	Train persuasion loss:0.02549	Train MAE Loss:0.13366
	Eval persuasion loss:0.02664	Eval MAE Loss:0.13383
[SAVE MODEL] eval pers loss: 0.02644	mini pers loss: 0.02664	eval acc: 0.1377	max_acc: 0.1338
Epoch: 02/40 | Time: 0m 13s
	Train persuasion loss:0.02165	Train MAE Loss:0.12042
	Eval persuasion loss:0.02644	Eval MAE Loss:0.13769
Epoch: 03/40 | Time: 0m 14s
	Train persuasion loss:0.01740	Train MAE Loss:0.10416
	Eval persuasion loss:0.03278	Eval MAE Loss:0.14765
Epoch: 04/40 | Time: 0m 13s
	Train persuasion loss:0.01684	Train MAE Loss:0.10139
	Eval persuasion loss:0.03946	Eval MAE Loss:0.15857
Epoch: 05/40 | Time: 0m 12s
	Train persuasion loss:0.01613	Train MAE Loss:0.09720
	Eval persuasion loss:0.03532	Eval MAE Loss:0.14523
Epoch: 06/40 | Time: 0m 13s
	Train persuasion loss:0.01480	Train MAE Loss:0.09499
	Eval persuasion loss:0.03653	Eval MAE Loss:0.15058
Epoch: 07/40 | Time: 0m 12s
	Train persuasion loss:0.01365	Train MAE Loss:0.08905
	Eval persuasion loss:0.04171	Eval MAE Loss:0.15287
Epoch: 08/40 | Time: 0m 12s
	Train persuasion loss:0.01322	Train MAE Loss:0.08814
	Eval persuasion loss:0.04203	Eval MAE Loss:0.15173
Epoch: 09/40 | Time: 0m 13s
	Train persuasion loss:0.01224	Train MAE Loss:0.08436
	Eval persuasion loss:0.04748	Eval MAE Loss:0.17735
Epoch: 10/40 | Time: 0m 13s
	Train persuasion loss:0.01194	Train MAE Loss:0.08430
	Eval persuasion loss:0.05159	Eval MAE Loss:0.17985
Epoch: 11/40 | Time: 0m 13s
	Train persuasion loss:0.01055	Train MAE Loss:0.07707
	Eval persuasion loss:0.04138	Eval MAE Loss:0.15360
Epoch: 12/40 | Time: 0m 12s
	Train persuasion loss:0.01003	Train MAE Loss:0.07526
	Eval persuasion loss:0.04393	Eval MAE Loss:0.16197
Epoch: 13/40 | Time: 0m 12s
	Train persuasion loss:0.00904	Train MAE Loss:0.07142
	Eval persuasion loss:0.04601	Eval MAE Loss:0.16630
Epoch: 14/40 | Time: 0m 12s
	Train persuasion loss:0.00896	Train MAE Loss:0.07263
	Eval persuasion loss:0.04823	Eval MAE Loss:0.17226
Epoch: 15/40 | Time: 0m 12s
	Train persuasion loss:0.00877	Train MAE Loss:0.06957
	Eval persuasion loss:0.04568	Eval MAE Loss:0.16528
Epoch: 16/40 | Time: 0m 13s
	Train persuasion loss:0.00873	Train MAE Loss:0.07084
	Eval persuasion loss:0.04731	Eval MAE Loss:0.16874
Epoch: 17/40 | Time: 0m 13s
	Train persuasion loss:0.00883	Train MAE Loss:0.07155
	Eval persuasion loss:0.04680	Eval MAE Loss:0.16822
Epoch: 18/40 | Time: 0m 13s
	Train persuasion loss:0.00831	Train MAE Loss:0.06861
	Eval persuasion loss:0.04925	Eval MAE Loss:0.17303
Epoch: 19/40 | Time: 0m 13s
	Train persuasion loss:0.00778	Train MAE Loss:0.06799
	Eval persuasion loss:0.04829	Eval MAE Loss:0.16789
Epoch: 20/40 | Time: 0m 13s
	Train persuasion loss:0.00795	Train MAE Loss:0.06810
	Eval persuasion loss:0.04698	Eval MAE Loss:0.16331
Epoch: 21/40 | Time: 0m 13s
	Train persuasion loss:0.00739	Train MAE Loss:0.06608
	Eval persuasion loss:0.04794	Eval MAE Loss:0.16679
Epoch: 22/40 | Time: 0m 13s
	Train persuasion loss:0.00721	Train MAE Loss:0.06396
	Eval persuasion loss:0.04930	Eval MAE Loss:0.17040
Epoch: 23/40 | Time: 0m 14s
	Train persuasion loss:0.00650	Train MAE Loss:0.06205
	Eval persuasion loss:0.04902	Eval MAE Loss:0.17001
Epoch: 24/40 | Time: 0m 13s
	Train persuasion loss:0.00747	Train MAE Loss:0.06578
	Eval persuasion loss:0.04897	Eval MAE Loss:0.16961
Epoch: 25/40 | Time: 0m 13s
	Train persuasion loss:0.00730	Train MAE Loss:0.06546
	Eval persuasion loss:0.04870	Eval MAE Loss:0.16870
Epoch: 26/40 | Time: 0m 13s
	Train persuasion loss:0.00654	Train MAE Loss:0.06237
	Eval persuasion loss:0.04830	Eval MAE Loss:0.16869
Epoch: 27/40 | Time: 0m 13s
	Train persuasion loss:0.00732	Train MAE Loss:0.06537
	Eval persuasion loss:0.04807	Eval MAE Loss:0.16984
Epoch: 28/40 | Time: 0m 12s
	Train persuasion loss:0.00675	Train MAE Loss:0.06376
	Eval persuasion loss:0.04760	Eval MAE Loss:0.16954
Epoch: 29/40 | Time: 0m 13s
	Train persuasion loss:0.00730	Train MAE Loss:0.06549
	Eval persuasion loss:0.04805	Eval MAE Loss:0.16908
Epoch: 30/40 | Time: 0m 13s
	Train persuasion loss:0.00675	Train MAE Loss:0.06255
	Eval persuasion loss:0.04916	Eval MAE Loss:0.17145
Epoch: 31/40 | Time: 0m 13s
	Train persuasion loss:0.00683	Train MAE Loss:0.06306
	Eval persuasion loss:0.04905	Eval MAE Loss:0.17120
Epoch: 32/40 | Time: 0m 12s
	Train persuasion loss:0.00635	Train MAE Loss:0.05990
	Eval persuasion loss:0.04896	Eval MAE Loss:0.17099
Epoch: 33/40 | Time: 0m 14s
	Train persuasion loss:0.00692	Train MAE Loss:0.06515
	Eval persuasion loss:0.04888	Eval MAE Loss:0.17091
Epoch: 34/40 | Time: 0m 13s
	Train persuasion loss:0.00679	Train MAE Loss:0.06176
	Eval persuasion loss:0.04880	Eval MAE Loss:0.17073
Epoch: 35/40 | Time: 0m 12s
	Train persuasion loss:0.00636	Train MAE Loss:0.05899
	Eval persuasion loss:0.04875	Eval MAE Loss:0.17056
Epoch: 36/40 | Time: 0m 13s
	Train persuasion loss:0.00675	Train MAE Loss:0.06180
	Eval persuasion loss:0.04858	Eval MAE Loss:0.16961
Epoch: 37/40 | Time: 0m 13s
	Train persuasion loss:0.00672	Train MAE Loss:0.06475
	Eval persuasion loss:0.04856	Eval MAE Loss:0.16944
Epoch: 38/40 | Time: 0m 13s
	Train persuasion loss:0.00690	Train MAE Loss:0.06452
	Eval persuasion loss:0.04871	Eval MAE Loss:0.16995
Epoch: 39/40 | Time: 0m 13s
	Train persuasion loss:0.00681	Train MAE Loss:0.06328
	Eval persuasion loss:0.04866	Eval MAE Loss:0.17045
Epoch: 40/40 | Time: 0m 12s
	Train persuasion loss:0.00700	Train MAE Loss:0.06329
	Eval persuasion loss:0.04862	Eval MAE Loss:0.17067
FOLD 4
Let's use 10 GPUs!
Test persuasion loss:0.02786	Test MAE Loss:0.14318
MSE: 0.028
FOLD 5
Let's use 10 GPUs!
####### total m2p2 hyper-parameters  924577
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(73, 32, kernel_size=(28,), stride=(3,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
70992
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(512, 32, kernel_size=(30,), stride=(5,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
497104
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(200, 32, kernel_size=(34,), stride=(9,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
223184
BiAttnModel(
  (trans_a_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_a_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (fc1): Linear(in_features=64, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=1, bias=False)
)
73920
TriAttnModel(
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=64, out_features=32, bias=True)
  (fc3): Linear(in_features=64, out_features=32, bias=True)
)
6240
PersModel(
  (fc1): Linear(in_features=162, out_features=324, bias=True)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc2): Linear(in_features=324, out_features=1, bias=True)
  (sigm): Sigmoid()
)
53137
[SAVE MODEL] eval pers loss: 0.01496	mini pers loss: 100000.00000	eval acc: 0.1099	max_acc: 0.0000
Epoch: 01/40 | Time: 0m 12s
	Train persuasion loss:0.02485	Train MAE Loss:0.12897
	Eval persuasion loss:0.01496	Eval MAE Loss:0.10994
Epoch: 02/40 | Time: 0m 13s
	Train persuasion loss:0.02093	Train MAE Loss:0.11571
	Eval persuasion loss:0.02608	Eval MAE Loss:0.13668
Epoch: 03/40 | Time: 0m 13s
	Train persuasion loss:0.01896	Train MAE Loss:0.10501
	Eval persuasion loss:0.01784	Eval MAE Loss:0.10559
Epoch: 04/40 | Time: 0m 12s
	Train persuasion loss:0.01671	Train MAE Loss:0.09945
	Eval persuasion loss:0.01753	Eval MAE Loss:0.10612
Epoch: 05/40 | Time: 0m 12s
	Train persuasion loss:0.01518	Train MAE Loss:0.09309
	Eval persuasion loss:0.02222	Eval MAE Loss:0.11759
Epoch: 06/40 | Time: 0m 15s
	Train persuasion loss:0.01436	Train MAE Loss:0.09099
	Eval persuasion loss:0.02106	Eval MAE Loss:0.11244
Epoch: 07/40 | Time: 0m 14s
	Train persuasion loss:0.01422	Train MAE Loss:0.09193
	Eval persuasion loss:0.02047	Eval MAE Loss:0.10750
Epoch: 08/40 | Time: 0m 12s
	Train persuasion loss:0.01255	Train MAE Loss:0.08470
	Eval persuasion loss:0.02270	Eval MAE Loss:0.11503
Epoch: 09/40 | Time: 0m 13s
	Train persuasion loss:0.01068	Train MAE Loss:0.07780
	Eval persuasion loss:0.02570	Eval MAE Loss:0.13363
Epoch: 10/40 | Time: 0m 11s
	Train persuasion loss:0.00975	Train MAE Loss:0.07558
	Eval persuasion loss:0.03526	Eval MAE Loss:0.16540
Epoch: 11/40 | Time: 0m 13s
	Train persuasion loss:0.00937	Train MAE Loss:0.07295
	Eval persuasion loss:0.02665	Eval MAE Loss:0.12528
Epoch: 12/40 | Time: 0m 18s
	Train persuasion loss:0.00881	Train MAE Loss:0.07240
	Eval persuasion loss:0.02987	Eval MAE Loss:0.13906
Epoch: 13/40 | Time: 0m 13s
	Train persuasion loss:0.00770	Train MAE Loss:0.06651
	Eval persuasion loss:0.03123	Eval MAE Loss:0.14345
Epoch: 14/40 | Time: 0m 17s
	Train persuasion loss:0.00806	Train MAE Loss:0.07093
	Eval persuasion loss:0.02758	Eval MAE Loss:0.12745
Epoch: 15/40 | Time: 0m 14s
	Train persuasion loss:0.00662	Train MAE Loss:0.06255
	Eval persuasion loss:0.02903	Eval MAE Loss:0.13352
Epoch: 16/40 | Time: 0m 9s
	Train persuasion loss:0.00747	Train MAE Loss:0.06490
	Eval persuasion loss:0.02688	Eval MAE Loss:0.12545
Epoch: 17/40 | Time: 0m 9s
	Train persuasion loss:0.00671	Train MAE Loss:0.06286
	Eval persuasion loss:0.02927	Eval MAE Loss:0.13293
Epoch: 18/40 | Time: 0m 12s
	Train persuasion loss:0.00630	Train MAE Loss:0.06074
	Eval persuasion loss:0.03158	Eval MAE Loss:0.13844
Epoch: 19/40 | Time: 0m 15s
	Train persuasion loss:0.00686	Train MAE Loss:0.06214
	Eval persuasion loss:0.03113	Eval MAE Loss:0.13600
Epoch: 20/40 | Time: 0m 15s
	Train persuasion loss:0.00610	Train MAE Loss:0.05989
	Eval persuasion loss:0.02943	Eval MAE Loss:0.13136
Epoch: 21/40 | Time: 0m 20s
	Train persuasion loss:0.00585	Train MAE Loss:0.05963
	Eval persuasion loss:0.03093	Eval MAE Loss:0.13517
Epoch: 22/40 | Time: 0m 20s
	Train persuasion loss:0.00547	Train MAE Loss:0.05595
	Eval persuasion loss:0.03100	Eval MAE Loss:0.13509
Epoch: 23/40 | Time: 0m 13s
	Train persuasion loss:0.00594	Train MAE Loss:0.05785
	Eval persuasion loss:0.03225	Eval MAE Loss:0.13902
Epoch: 24/40 | Time: 0m 22s
	Train persuasion loss:0.00603	Train MAE Loss:0.05860
	Eval persuasion loss:0.03103	Eval MAE Loss:0.13509
Epoch: 25/40 | Time: 0m 14s
	Train persuasion loss:0.00553	Train MAE Loss:0.05605
	Eval persuasion loss:0.02974	Eval MAE Loss:0.13177
Epoch: 26/40 | Time: 0m 19s
	Train persuasion loss:0.00570	Train MAE Loss:0.05792
	Eval persuasion loss:0.02986	Eval MAE Loss:0.13167
Epoch: 27/40 | Time: 0m 16s
	Train persuasion loss:0.00556	Train MAE Loss:0.05827
	Eval persuasion loss:0.03021	Eval MAE Loss:0.13326
Epoch: 28/40 | Time: 0m 21s
	Train persuasion loss:0.00552	Train MAE Loss:0.05615
	Eval persuasion loss:0.03054	Eval MAE Loss:0.13465
Epoch: 29/40 | Time: 0m 25s
	Train persuasion loss:0.00567	Train MAE Loss:0.05804
	Eval persuasion loss:0.03138	Eval MAE Loss:0.13678
Epoch: 30/40 | Time: 0m 24s
	Train persuasion loss:0.00523	Train MAE Loss:0.05649
	Eval persuasion loss:0.03012	Eval MAE Loss:0.13342
Epoch: 31/40 | Time: 0m 14s
	Train persuasion loss:0.00543	Train MAE Loss:0.05767
	Eval persuasion loss:0.03043	Eval MAE Loss:0.13418
Epoch: 32/40 | Time: 0m 12s
	Train persuasion loss:0.00530	Train MAE Loss:0.05700
	Eval persuasion loss:0.03067	Eval MAE Loss:0.13476
Epoch: 33/40 | Time: 0m 12s
	Train persuasion loss:0.00615	Train MAE Loss:0.06100
	Eval persuasion loss:0.03078	Eval MAE Loss:0.13512
Epoch: 34/40 | Time: 0m 16s
	Train persuasion loss:0.00504	Train MAE Loss:0.05567
	Eval persuasion loss:0.03037	Eval MAE Loss:0.13376
Epoch: 35/40 | Time: 0m 25s
	Train persuasion loss:0.00491	Train MAE Loss:0.05516
	Eval persuasion loss:0.03034	Eval MAE Loss:0.13365
Epoch: 36/40 | Time: 0m 15s
	Train persuasion loss:0.00565	Train MAE Loss:0.05728
	Eval persuasion loss:0.03037	Eval MAE Loss:0.13369
Epoch: 37/40 | Time: 0m 13s
	Train persuasion loss:0.00484	Train MAE Loss:0.05337
	Eval persuasion loss:0.03025	Eval MAE Loss:0.13336
Epoch: 38/40 | Time: 0m 10s
	Train persuasion loss:0.00569	Train MAE Loss:0.05776
	Eval persuasion loss:0.03032	Eval MAE Loss:0.13354
Epoch: 39/40 | Time: 0m 16s
	Train persuasion loss:0.00510	Train MAE Loss:0.05457
	Eval persuasion loss:0.03035	Eval MAE Loss:0.13354
Epoch: 40/40 | Time: 0m 21s
	Train persuasion loss:0.00542	Train MAE Loss:0.05597
	Eval persuasion loss:0.03014	Eval MAE Loss:0.13294
FOLD 5
Let's use 10 GPUs!
Test persuasion loss:0.02058	Test MAE Loss:0.12497
MSE: 0.021
FOLD 6
Let's use 10 GPUs!
####### total m2p2 hyper-parameters  924577
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(73, 32, kernel_size=(28,), stride=(3,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
70992
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(512, 32, kernel_size=(30,), stride=(5,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
497104
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(200, 32, kernel_size=(34,), stride=(9,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
223184
BiAttnModel(
  (trans_a_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_a_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (fc1): Linear(in_features=64, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=1, bias=False)
)
73920
TriAttnModel(
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=64, out_features=32, bias=True)
  (fc3): Linear(in_features=64, out_features=32, bias=True)
)
6240
PersModel(
  (fc1): Linear(in_features=162, out_features=324, bias=True)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc2): Linear(in_features=324, out_features=1, bias=True)
  (sigm): Sigmoid()
)
53137
[SAVE MODEL] eval pers loss: 0.02798	mini pers loss: 100000.00000	eval acc: 0.1406	max_acc: 0.0000
Epoch: 01/40 | Time: 0m 12s
	Train persuasion loss:0.02624	Train MAE Loss:0.13092
	Eval persuasion loss:0.02798	Eval MAE Loss:0.14058
Epoch: 02/40 | Time: 0m 7s
	Train persuasion loss:0.02280	Train MAE Loss:0.12220
	Eval persuasion loss:0.03795	Eval MAE Loss:0.16151
Epoch: 03/40 | Time: 0m 7s
	Train persuasion loss:0.01898	Train MAE Loss:0.10792
	Eval persuasion loss:0.04104	Eval MAE Loss:0.17257
Epoch: 04/40 | Time: 0m 7s
	Train persuasion loss:0.01753	Train MAE Loss:0.10007
	Eval persuasion loss:0.04368	Eval MAE Loss:0.16816
Epoch: 05/40 | Time: 0m 7s
	Train persuasion loss:0.01601	Train MAE Loss:0.09684
	Eval persuasion loss:0.04183	Eval MAE Loss:0.17657
Epoch: 06/40 | Time: 0m 7s
	Train persuasion loss:0.01484	Train MAE Loss:0.09104
	Eval persuasion loss:0.04733	Eval MAE Loss:0.19513
Epoch: 07/40 | Time: 0m 7s
	Train persuasion loss:0.01305	Train MAE Loss:0.08579
	Eval persuasion loss:0.05258	Eval MAE Loss:0.20791
Epoch: 08/40 | Time: 0m 7s
	Train persuasion loss:0.01259	Train MAE Loss:0.08160
	Eval persuasion loss:0.04826	Eval MAE Loss:0.19406
Epoch: 09/40 | Time: 0m 7s
	Train persuasion loss:0.01092	Train MAE Loss:0.07760
	Eval persuasion loss:0.05845	Eval MAE Loss:0.20806
Epoch: 10/40 | Time: 0m 7s
	Train persuasion loss:0.01118	Train MAE Loss:0.08094
	Eval persuasion loss:0.06877	Eval MAE Loss:0.22599
Epoch: 11/40 | Time: 0m 7s
	Train persuasion loss:0.00968	Train MAE Loss:0.07432
	Eval persuasion loss:0.06819	Eval MAE Loss:0.22178
Epoch: 12/40 | Time: 0m 7s
	Train persuasion loss:0.00901	Train MAE Loss:0.07081
	Eval persuasion loss:0.06952	Eval MAE Loss:0.22132
Epoch: 13/40 | Time: 0m 14s
	Train persuasion loss:0.00818	Train MAE Loss:0.06856
	Eval persuasion loss:0.07201	Eval MAE Loss:0.23369
Epoch: 14/40 | Time: 0m 12s
	Train persuasion loss:0.00799	Train MAE Loss:0.06752
	Eval persuasion loss:0.07162	Eval MAE Loss:0.22650
Epoch: 15/40 | Time: 0m 12s
	Train persuasion loss:0.00831	Train MAE Loss:0.06885
	Eval persuasion loss:0.07201	Eval MAE Loss:0.22903
Epoch: 16/40 | Time: 0m 11s
	Train persuasion loss:0.00771	Train MAE Loss:0.06648
	Eval persuasion loss:0.07008	Eval MAE Loss:0.22810
Epoch: 17/40 | Time: 0m 7s
	Train persuasion loss:0.00716	Train MAE Loss:0.06343
	Eval persuasion loss:0.07152	Eval MAE Loss:0.22556
Epoch: 18/40 | Time: 0m 7s
	Train persuasion loss:0.00702	Train MAE Loss:0.06557
	Eval persuasion loss:0.07247	Eval MAE Loss:0.23589
Epoch: 19/40 | Time: 0m 8s
	Train persuasion loss:0.00707	Train MAE Loss:0.06507
	Eval persuasion loss:0.06860	Eval MAE Loss:0.22111
Epoch: 20/40 | Time: 0m 8s
	Train persuasion loss:0.00735	Train MAE Loss:0.06483
	Eval persuasion loss:0.07185	Eval MAE Loss:0.23127
Epoch: 21/40 | Time: 0m 10s
	Train persuasion loss:0.00652	Train MAE Loss:0.06311
	Eval persuasion loss:0.07132	Eval MAE Loss:0.22881
Epoch: 22/40 | Time: 0m 7s
	Train persuasion loss:0.00622	Train MAE Loss:0.06032
	Eval persuasion loss:0.07181	Eval MAE Loss:0.23124
Epoch: 23/40 | Time: 0m 8s
	Train persuasion loss:0.00624	Train MAE Loss:0.06086
	Eval persuasion loss:0.07141	Eval MAE Loss:0.23025
Epoch: 24/40 | Time: 0m 7s
	Train persuasion loss:0.00615	Train MAE Loss:0.06193
	Eval persuasion loss:0.07100	Eval MAE Loss:0.22943
Epoch: 25/40 | Time: 0m 9s
	Train persuasion loss:0.00612	Train MAE Loss:0.05829
	Eval persuasion loss:0.07133	Eval MAE Loss:0.23082
Epoch: 26/40 | Time: 0m 8s
	Train persuasion loss:0.00625	Train MAE Loss:0.06161
	Eval persuasion loss:0.07172	Eval MAE Loss:0.23338
Epoch: 27/40 | Time: 0m 6s
	Train persuasion loss:0.00577	Train MAE Loss:0.05750
	Eval persuasion loss:0.07214	Eval MAE Loss:0.23298
Epoch: 28/40 | Time: 0m 7s
	Train persuasion loss:0.00601	Train MAE Loss:0.05925
	Eval persuasion loss:0.07312	Eval MAE Loss:0.23384
Epoch: 29/40 | Time: 0m 10s
	Train persuasion loss:0.00593	Train MAE Loss:0.05761
	Eval persuasion loss:0.07248	Eval MAE Loss:0.23320
Epoch: 30/40 | Time: 0m 14s
	Train persuasion loss:0.00555	Train MAE Loss:0.05872
	Eval persuasion loss:0.07349	Eval MAE Loss:0.23531
Epoch: 31/40 | Time: 0m 20s
	Train persuasion loss:0.00596	Train MAE Loss:0.05991
	Eval persuasion loss:0.07339	Eval MAE Loss:0.23528
Epoch: 32/40 | Time: 0m 15s
	Train persuasion loss:0.00590	Train MAE Loss:0.05792
	Eval persuasion loss:0.07326	Eval MAE Loss:0.23486
Epoch: 33/40 | Time: 0m 10s
	Train persuasion loss:0.00615	Train MAE Loss:0.05970
	Eval persuasion loss:0.07336	Eval MAE Loss:0.23504
Epoch: 34/40 | Time: 0m 17s
	Train persuasion loss:0.00578	Train MAE Loss:0.05679
	Eval persuasion loss:0.07328	Eval MAE Loss:0.23531
Epoch: 35/40 | Time: 0m 13s
	Train persuasion loss:0.00608	Train MAE Loss:0.06020
	Eval persuasion loss:0.07320	Eval MAE Loss:0.23495
Epoch: 36/40 | Time: 0m 11s
	Train persuasion loss:0.00578	Train MAE Loss:0.05666
	Eval persuasion loss:0.07321	Eval MAE Loss:0.23459
Epoch: 37/40 | Time: 0m 12s
	Train persuasion loss:0.00540	Train MAE Loss:0.05590
	Eval persuasion loss:0.07306	Eval MAE Loss:0.23395
Epoch: 38/40 | Time: 0m 11s
	Train persuasion loss:0.00547	Train MAE Loss:0.05796
	Eval persuasion loss:0.07310	Eval MAE Loss:0.23410
Epoch: 39/40 | Time: 0m 11s
	Train persuasion loss:0.00534	Train MAE Loss:0.05629
	Eval persuasion loss:0.07328	Eval MAE Loss:0.23463
Epoch: 40/40 | Time: 0m 11s
	Train persuasion loss:0.00575	Train MAE Loss:0.05692
	Eval persuasion loss:0.07315	Eval MAE Loss:0.23452
FOLD 6
Let's use 10 GPUs!
Test persuasion loss:0.01737	Test MAE Loss:0.12324
MSE: 0.017
FOLD 7
Let's use 10 GPUs!
####### total m2p2 hyper-parameters  924577
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(73, 32, kernel_size=(28,), stride=(3,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
70992
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(512, 32, kernel_size=(30,), stride=(5,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
497104
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(200, 32, kernel_size=(34,), stride=(9,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
223184
BiAttnModel(
  (trans_a_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_a_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (fc1): Linear(in_features=64, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=1, bias=False)
)
73920
TriAttnModel(
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=64, out_features=32, bias=True)
  (fc3): Linear(in_features=64, out_features=32, bias=True)
)
6240
PersModel(
  (fc1): Linear(in_features=162, out_features=324, bias=True)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc2): Linear(in_features=324, out_features=1, bias=True)
  (sigm): Sigmoid()
)
53137
[SAVE MODEL] eval pers loss: 0.01775	mini pers loss: 100000.00000	eval acc: 0.1251	max_acc: 0.0000
Epoch: 01/40 | Time: 0m 19s
	Train persuasion loss:0.02637	Train MAE Loss:0.13236
	Eval persuasion loss:0.01775	Eval MAE Loss:0.12506
[SAVE MODEL] eval pers loss: 0.01642	mini pers loss: 0.01775	eval acc: 0.1118	max_acc: 0.1251
Epoch: 02/40 | Time: 0m 11s
	Train persuasion loss:0.02217	Train MAE Loss:0.11904
	Eval persuasion loss:0.01642	Eval MAE Loss:0.11181
Epoch: 03/40 | Time: 0m 11s
	Train persuasion loss:0.02015	Train MAE Loss:0.11067
	Eval persuasion loss:0.02211	Eval MAE Loss:0.13399
Epoch: 04/40 | Time: 0m 11s
	Train persuasion loss:0.01854	Train MAE Loss:0.10391
	Eval persuasion loss:0.02137	Eval MAE Loss:0.12441
[SAVE MODEL] eval pers loss: 0.01630	mini pers loss: 0.01642	eval acc: 0.1027	max_acc: 0.1118
Epoch: 05/40 | Time: 0m 12s
	Train persuasion loss:0.01753	Train MAE Loss:0.10044
	Eval persuasion loss:0.01630	Eval MAE Loss:0.10267
Epoch: 06/40 | Time: 0m 11s
	Train persuasion loss:0.01552	Train MAE Loss:0.09290
	Eval persuasion loss:0.01901	Eval MAE Loss:0.10569
Epoch: 07/40 | Time: 0m 11s
	Train persuasion loss:0.01280	Train MAE Loss:0.08497
	Eval persuasion loss:0.02412	Eval MAE Loss:0.12765
Epoch: 08/40 | Time: 0m 12s
	Train persuasion loss:0.01188	Train MAE Loss:0.08071
	Eval persuasion loss:0.02971	Eval MAE Loss:0.14129
Epoch: 09/40 | Time: 0m 12s
	Train persuasion loss:0.01366	Train MAE Loss:0.08669
	Eval persuasion loss:0.02929	Eval MAE Loss:0.14902
Epoch: 10/40 | Time: 0m 16s
	Train persuasion loss:0.01160	Train MAE Loss:0.08049
	Eval persuasion loss:0.02652	Eval MAE Loss:0.13987
Epoch: 11/40 | Time: 0m 13s
	Train persuasion loss:0.01010	Train MAE Loss:0.07461
	Eval persuasion loss:0.03025	Eval MAE Loss:0.14381
Epoch: 12/40 | Time: 0m 11s
	Train persuasion loss:0.00876	Train MAE Loss:0.06752
	Eval persuasion loss:0.03082	Eval MAE Loss:0.14850
Epoch: 13/40 | Time: 0m 11s
	Train persuasion loss:0.00903	Train MAE Loss:0.06923
	Eval persuasion loss:0.03360	Eval MAE Loss:0.15558
Epoch: 14/40 | Time: 0m 12s
	Train persuasion loss:0.00879	Train MAE Loss:0.06836
	Eval persuasion loss:0.03610	Eval MAE Loss:0.16040
Epoch: 15/40 | Time: 0m 11s
	Train persuasion loss:0.00845	Train MAE Loss:0.06716
	Eval persuasion loss:0.03567	Eval MAE Loss:0.15682
Epoch: 16/40 | Time: 0m 10s
	Train persuasion loss:0.00793	Train MAE Loss:0.06708
	Eval persuasion loss:0.03819	Eval MAE Loss:0.16463
Epoch: 17/40 | Time: 0m 17s
	Train persuasion loss:0.00740	Train MAE Loss:0.06373
	Eval persuasion loss:0.03477	Eval MAE Loss:0.15618
Epoch: 18/40 | Time: 0m 12s
	Train persuasion loss:0.00715	Train MAE Loss:0.06166
	Eval persuasion loss:0.03997	Eval MAE Loss:0.17078
Epoch: 19/40 | Time: 0m 11s
	Train persuasion loss:0.00678	Train MAE Loss:0.06111
	Eval persuasion loss:0.03580	Eval MAE Loss:0.16164
Epoch: 20/40 | Time: 0m 16s
	Train persuasion loss:0.00707	Train MAE Loss:0.06284
	Eval persuasion loss:0.04236	Eval MAE Loss:0.17345
Epoch: 21/40 | Time: 0m 18s
	Train persuasion loss:0.00717	Train MAE Loss:0.06132
	Eval persuasion loss:0.04070	Eval MAE Loss:0.16829
Epoch: 22/40 | Time: 0m 14s
	Train persuasion loss:0.00598	Train MAE Loss:0.05814
	Eval persuasion loss:0.03684	Eval MAE Loss:0.16197
Epoch: 23/40 | Time: 0m 12s
	Train persuasion loss:0.00620	Train MAE Loss:0.05883
	Eval persuasion loss:0.03686	Eval MAE Loss:0.16209
Epoch: 24/40 | Time: 0m 11s
	Train persuasion loss:0.00632	Train MAE Loss:0.05976
	Eval persuasion loss:0.03741	Eval MAE Loss:0.16326
Epoch: 25/40 | Time: 0m 11s
	Train persuasion loss:0.00615	Train MAE Loss:0.05984
	Eval persuasion loss:0.03839	Eval MAE Loss:0.16603
Epoch: 26/40 | Time: 0m 14s
	Train persuasion loss:0.00582	Train MAE Loss:0.05671
	Eval persuasion loss:0.03935	Eval MAE Loss:0.16765
Epoch: 27/40 | Time: 0m 18s
	Train persuasion loss:0.00617	Train MAE Loss:0.05820
	Eval persuasion loss:0.03846	Eval MAE Loss:0.16616
Epoch: 28/40 | Time: 0m 18s
	Train persuasion loss:0.00519	Train MAE Loss:0.05410
	Eval persuasion loss:0.04029	Eval MAE Loss:0.16931
Epoch: 29/40 | Time: 0m 18s
	Train persuasion loss:0.00611	Train MAE Loss:0.05670
	Eval persuasion loss:0.04106	Eval MAE Loss:0.17070
Epoch: 30/40 | Time: 0m 18s
	Train persuasion loss:0.00585	Train MAE Loss:0.05785
	Eval persuasion loss:0.03983	Eval MAE Loss:0.16766
Epoch: 31/40 | Time: 0m 11s
	Train persuasion loss:0.00564	Train MAE Loss:0.05675
	Eval persuasion loss:0.03974	Eval MAE Loss:0.16757
Epoch: 32/40 | Time: 0m 19s
	Train persuasion loss:0.00556	Train MAE Loss:0.05598
	Eval persuasion loss:0.03973	Eval MAE Loss:0.16759
Epoch: 33/40 | Time: 0m 21s
	Train persuasion loss:0.00591	Train MAE Loss:0.05780
	Eval persuasion loss:0.03985	Eval MAE Loss:0.16771
Epoch: 34/40 | Time: 0m 15s
	Train persuasion loss:0.00589	Train MAE Loss:0.05725
	Eval persuasion loss:0.04014	Eval MAE Loss:0.16850
Epoch: 35/40 | Time: 0m 12s
	Train persuasion loss:0.00594	Train MAE Loss:0.05772
	Eval persuasion loss:0.04061	Eval MAE Loss:0.16984
Epoch: 36/40 | Time: 0m 12s
	Train persuasion loss:0.00598	Train MAE Loss:0.06010
	Eval persuasion loss:0.04058	Eval MAE Loss:0.16986
Epoch: 37/40 | Time: 0m 22s
	Train persuasion loss:0.00562	Train MAE Loss:0.05761
	Eval persuasion loss:0.04021	Eval MAE Loss:0.16916
Epoch: 38/40 | Time: 0m 15s
	Train persuasion loss:0.00540	Train MAE Loss:0.05639
	Eval persuasion loss:0.04000	Eval MAE Loss:0.16872
Epoch: 39/40 | Time: 0m 13s
	Train persuasion loss:0.00569	Train MAE Loss:0.05801
	Eval persuasion loss:0.04006	Eval MAE Loss:0.16886
Epoch: 40/40 | Time: 0m 12s
	Train persuasion loss:0.00555	Train MAE Loss:0.05493
	Eval persuasion loss:0.03997	Eval MAE Loss:0.16851
FOLD 7
Let's use 10 GPUs!
Test persuasion loss:0.03376	Test MAE Loss:0.15887
MSE: 0.034
FOLD 8
Let's use 10 GPUs!
####### total m2p2 hyper-parameters  924577
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(73, 32, kernel_size=(28,), stride=(3,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
70992
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(512, 32, kernel_size=(30,), stride=(5,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
497104
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(200, 32, kernel_size=(34,), stride=(9,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
223184
BiAttnModel(
  (trans_a_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_a_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (fc1): Linear(in_features=64, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=1, bias=False)
)
73920
TriAttnModel(
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=64, out_features=32, bias=True)
  (fc3): Linear(in_features=64, out_features=32, bias=True)
)
6240
PersModel(
  (fc1): Linear(in_features=162, out_features=324, bias=True)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc2): Linear(in_features=324, out_features=1, bias=True)
  (sigm): Sigmoid()
)
53137
[SAVE MODEL] eval pers loss: 0.02088	mini pers loss: 100000.00000	eval acc: 0.1369	max_acc: 0.0000
Epoch: 01/40 | Time: 0m 21s
	Train persuasion loss:0.02704	Train MAE Loss:0.13012
	Eval persuasion loss:0.02088	Eval MAE Loss:0.13691
[SAVE MODEL] eval pers loss: 0.01536	mini pers loss: 0.02088	eval acc: 0.1105	max_acc: 0.1369
Epoch: 02/40 | Time: 0m 19s
	Train persuasion loss:0.02458	Train MAE Loss:0.12403
	Eval persuasion loss:0.01536	Eval MAE Loss:0.11053
[SAVE MODEL] eval pers loss: 0.01345	mini pers loss: 0.01536	eval acc: 0.1003	max_acc: 0.1105
Epoch: 03/40 | Time: 0m 23s
	Train persuasion loss:0.02178	Train MAE Loss:0.11597
	Eval persuasion loss:0.01345	Eval MAE Loss:0.10031
Epoch: 04/40 | Time: 0m 25s
	Train persuasion loss:0.01925	Train MAE Loss:0.10654
	Eval persuasion loss:0.01619	Eval MAE Loss:0.11550
[SAVE MODEL] eval pers loss: 0.01316	mini pers loss: 0.01345	eval acc: 0.0941	max_acc: 0.1003
Epoch: 05/40 | Time: 0m 30s
	Train persuasion loss:0.01862	Train MAE Loss:0.10645
	Eval persuasion loss:0.01316	Eval MAE Loss:0.09409
Epoch: 06/40 | Time: 0m 28s
	Train persuasion loss:0.01758	Train MAE Loss:0.10008
	Eval persuasion loss:0.01557	Eval MAE Loss:0.10541
Epoch: 07/40 | Time: 0m 12s
	Train persuasion loss:0.01666	Train MAE Loss:0.10018
	Eval persuasion loss:0.01686	Eval MAE Loss:0.11059
[SAVE MODEL] eval pers loss: 0.01049	mini pers loss: 0.01316	eval acc: 0.0718	max_acc: 0.0941
Epoch: 08/40 | Time: 0m 13s
	Train persuasion loss:0.01698	Train MAE Loss:0.09627
	Eval persuasion loss:0.01049	Eval MAE Loss:0.07178
Epoch: 09/40 | Time: 0m 12s
	Train persuasion loss:0.01633	Train MAE Loss:0.09601
	Eval persuasion loss:0.02618	Eval MAE Loss:0.13988
Epoch: 10/40 | Time: 0m 11s
	Train persuasion loss:0.01333	Train MAE Loss:0.08765
	Eval persuasion loss:0.01929	Eval MAE Loss:0.12497
Epoch: 11/40 | Time: 0m 11s
	Train persuasion loss:0.01156	Train MAE Loss:0.08040
	Eval persuasion loss:0.01703	Eval MAE Loss:0.11595
Epoch: 12/40 | Time: 0m 12s
	Train persuasion loss:0.01255	Train MAE Loss:0.07980
	Eval persuasion loss:0.01428	Eval MAE Loss:0.10207
Epoch: 13/40 | Time: 0m 12s
	Train persuasion loss:0.01099	Train MAE Loss:0.07687
	Eval persuasion loss:0.01810	Eval MAE Loss:0.12093
Epoch: 14/40 | Time: 0m 12s
	Train persuasion loss:0.01051	Train MAE Loss:0.07624
	Eval persuasion loss:0.01696	Eval MAE Loss:0.11417
Epoch: 15/40 | Time: 0m 10s
	Train persuasion loss:0.01014	Train MAE Loss:0.07462
	Eval persuasion loss:0.01514	Eval MAE Loss:0.10314
Epoch: 16/40 | Time: 0m 12s
	Train persuasion loss:0.01009	Train MAE Loss:0.07644
	Eval persuasion loss:0.01825	Eval MAE Loss:0.11825
Epoch: 17/40 | Time: 0m 15s
	Train persuasion loss:0.00943	Train MAE Loss:0.07288
	Eval persuasion loss:0.01675	Eval MAE Loss:0.10490
Epoch: 18/40 | Time: 0m 12s
	Train persuasion loss:0.00898	Train MAE Loss:0.07048
	Eval persuasion loss:0.01876	Eval MAE Loss:0.11422
Epoch: 19/40 | Time: 0m 11s
	Train persuasion loss:0.00788	Train MAE Loss:0.06594
	Eval persuasion loss:0.01934	Eval MAE Loss:0.11519
Epoch: 20/40 | Time: 0m 12s
	Train persuasion loss:0.00799	Train MAE Loss:0.06754
	Eval persuasion loss:0.01808	Eval MAE Loss:0.10992
Epoch: 21/40 | Time: 0m 11s
	Train persuasion loss:0.00792	Train MAE Loss:0.06905
	Eval persuasion loss:0.01875	Eval MAE Loss:0.11114
Epoch: 22/40 | Time: 0m 14s
	Train persuasion loss:0.00772	Train MAE Loss:0.06658
	Eval persuasion loss:0.01983	Eval MAE Loss:0.11562
Epoch: 23/40 | Time: 0m 18s
	Train persuasion loss:0.00835	Train MAE Loss:0.07075
	Eval persuasion loss:0.01981	Eval MAE Loss:0.11628
Epoch: 24/40 | Time: 0m 12s
	Train persuasion loss:0.00743	Train MAE Loss:0.06586
	Eval persuasion loss:0.01944	Eval MAE Loss:0.11452
Epoch: 25/40 | Time: 0m 10s
	Train persuasion loss:0.00791	Train MAE Loss:0.06571
	Eval persuasion loss:0.01864	Eval MAE Loss:0.11033
Epoch: 26/40 | Time: 0m 15s
	Train persuasion loss:0.00723	Train MAE Loss:0.06548
	Eval persuasion loss:0.02101	Eval MAE Loss:0.11884
Epoch: 27/40 | Time: 0m 9s
	Train persuasion loss:0.00710	Train MAE Loss:0.06155
	Eval persuasion loss:0.02024	Eval MAE Loss:0.11634
Epoch: 28/40 | Time: 0m 10s
	Train persuasion loss:0.00715	Train MAE Loss:0.06244
	Eval persuasion loss:0.01917	Eval MAE Loss:0.11155
Epoch: 29/40 | Time: 0m 11s
	Train persuasion loss:0.00732	Train MAE Loss:0.06454
	Eval persuasion loss:0.01936	Eval MAE Loss:0.11112
Epoch: 30/40 | Time: 0m 11s
	Train persuasion loss:0.00741	Train MAE Loss:0.06509
	Eval persuasion loss:0.01922	Eval MAE Loss:0.11080
Epoch: 31/40 | Time: 0m 15s
	Train persuasion loss:0.00689	Train MAE Loss:0.06366
	Eval persuasion loss:0.01932	Eval MAE Loss:0.11108
Epoch: 32/40 | Time: 0m 15s
	Train persuasion loss:0.00706	Train MAE Loss:0.06203
	Eval persuasion loss:0.01932	Eval MAE Loss:0.11107
Epoch: 33/40 | Time: 0m 18s
	Train persuasion loss:0.00643	Train MAE Loss:0.06256
	Eval persuasion loss:0.01947	Eval MAE Loss:0.11148
Epoch: 34/40 | Time: 0m 13s
	Train persuasion loss:0.00731	Train MAE Loss:0.06678
	Eval persuasion loss:0.01965	Eval MAE Loss:0.11204
Epoch: 35/40 | Time: 0m 12s
	Train persuasion loss:0.00759	Train MAE Loss:0.06641
	Eval persuasion loss:0.01976	Eval MAE Loss:0.11243
Epoch: 36/40 | Time: 0m 11s
	Train persuasion loss:0.00686	Train MAE Loss:0.06332
	Eval persuasion loss:0.01990	Eval MAE Loss:0.11316
Epoch: 37/40 | Time: 0m 12s
	Train persuasion loss:0.00669	Train MAE Loss:0.06204
	Eval persuasion loss:0.02007	Eval MAE Loss:0.11371
Epoch: 38/40 | Time: 0m 11s
	Train persuasion loss:0.00653	Train MAE Loss:0.06033
	Eval persuasion loss:0.02005	Eval MAE Loss:0.11329
Epoch: 39/40 | Time: 0m 12s
	Train persuasion loss:0.00649	Train MAE Loss:0.06196
	Eval persuasion loss:0.02015	Eval MAE Loss:0.11345
Epoch: 40/40 | Time: 0m 12s
	Train persuasion loss:0.00700	Train MAE Loss:0.06351
	Eval persuasion loss:0.02028	Eval MAE Loss:0.11376
FOLD 8
Let's use 10 GPUs!
Test persuasion loss:0.01364	Test MAE Loss:0.09766
MSE: 0.014
FOLD 9
Let's use 10 GPUs!
####### total m2p2 hyper-parameters  924577
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(73, 32, kernel_size=(28,), stride=(3,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
70992
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(512, 32, kernel_size=(30,), stride=(5,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
497104
LatentModel(
  (feat_exa): InputEmb(
    (conv1): Conv1d(200, 32, kernel_size=(34,), stride=(9,))
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (transformer_emb): TransformerEmb(
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.4, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=32, out_features=32, bias=True)
          )
          (linear1): Linear(in_features=32, out_features=16, bias=True)
          (dropout): Dropout(p=0.4, inplace=False)
          (linear2): Linear(in_features=16, out_features=32, bias=True)
          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.4, inplace=False)
          (dropout2): Dropout(p=0.4, inplace=False)
        )
      )
    )
  )
)
223184
BiAttnModel(
  (trans_a_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_a_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_v_with_l): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_a): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (trans_l_with_v): CrossAttnModel(
    (ln_alpha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ln_beta): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (weightQ): Linear(in_features=32, out_features=32, bias=False)
    (weightK): Linear(in_features=32, out_features=32, bias=False)
    (weightV): Linear(in_features=32, out_features=32, bias=False)
    (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (fc1): Linear(in_features=32, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=32, bias=True)
    (dropout): Dropout(p=0.4, inplace=False)
  )
  (fc1): Linear(in_features=64, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=1, bias=False)
)
73920
TriAttnModel(
  (fc1): Linear(in_features=64, out_features=32, bias=True)
  (fc2): Linear(in_features=64, out_features=32, bias=True)
  (fc3): Linear(in_features=64, out_features=32, bias=True)
)
6240
PersModel(
  (fc1): Linear(in_features=162, out_features=324, bias=True)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc2): Linear(in_features=324, out_features=1, bias=True)
  (sigm): Sigmoid()
)
53137
[SAVE MODEL] eval pers loss: 0.02150	mini pers loss: 100000.00000	eval acc: 0.0921	max_acc: 0.0000
Epoch: 01/40 | Time: 0m 28s
	Train persuasion loss:0.02175	Train MAE Loss:0.12040
	Eval persuasion loss:0.02150	Eval MAE Loss:0.09215
Epoch: 02/40 | Time: 0m 11s
	Train persuasion loss:0.01934	Train MAE Loss:0.11458
	Eval persuasion loss:0.02210	Eval MAE Loss:0.11175
Epoch: 03/40 | Time: 0m 11s
	Train persuasion loss:0.01719	Train MAE Loss:0.10370
	Eval persuasion loss:0.04001	Eval MAE Loss:0.17112
[SAVE MODEL] eval pers loss: 0.01947	mini pers loss: 0.02150	eval acc: 0.0899	max_acc: 0.0921
Epoch: 04/40 | Time: 0m 10s
	Train persuasion loss:0.01563	Train MAE Loss:0.10007
	Eval persuasion loss:0.01947	Eval MAE Loss:0.08994
Epoch: 05/40 | Time: 0m 12s
	Train persuasion loss:0.01370	Train MAE Loss:0.09069
	Eval persuasion loss:0.02187	Eval MAE Loss:0.10126
Epoch: 06/40 | Time: 0m 10s
	Train persuasion loss:0.01218	Train MAE Loss:0.08650
	Eval persuasion loss:0.02094	Eval MAE Loss:0.08862
Epoch: 07/40 | Time: 0m 10s
	Train persuasion loss:0.01157	Train MAE Loss:0.08288
	Eval persuasion loss:0.02312	Eval MAE Loss:0.11153
Epoch: 08/40 | Time: 0m 10s
	Train persuasion loss:0.01035	Train MAE Loss:0.07981
	Eval persuasion loss:0.03741	Eval MAE Loss:0.16822
Epoch: 09/40 | Time: 0m 14s
	Train persuasion loss:0.01147	Train MAE Loss:0.08781
	Eval persuasion loss:0.02036	Eval MAE Loss:0.09364
Epoch: 10/40 | Time: 0m 13s
	Train persuasion loss:0.00932	Train MAE Loss:0.07574
	Eval persuasion loss:0.01986	Eval MAE Loss:0.09295
Epoch: 11/40 | Time: 0m 14s
	Train persuasion loss:0.00753	Train MAE Loss:0.06811
	Eval persuasion loss:0.02059	Eval MAE Loss:0.09151
Epoch: 12/40 | Time: 0m 13s
	Train persuasion loss:0.00742	Train MAE Loss:0.06782
	Eval persuasion loss:0.02346	Eval MAE Loss:0.11913
Epoch: 13/40 | Time: 0m 16s
	Train persuasion loss:0.00712	Train MAE Loss:0.06623
	Eval persuasion loss:0.02429	Eval MAE Loss:0.12498
Epoch: 14/40 | Time: 0m 13s
	Train persuasion loss:0.00649	Train MAE Loss:0.06386
	Eval persuasion loss:0.02737	Eval MAE Loss:0.13869
Epoch: 15/40 | Time: 0m 13s
	Train persuasion loss:0.00654	Train MAE Loss:0.06399
	Eval persuasion loss:0.02792	Eval MAE Loss:0.14124
Epoch: 16/40 | Time: 0m 12s
	Train persuasion loss:0.00664	Train MAE Loss:0.06408
	Eval persuasion loss:0.02843	Eval MAE Loss:0.14293
Epoch: 17/40 | Time: 0m 11s
	Train persuasion loss:0.00585	Train MAE Loss:0.05913
	Eval persuasion loss:0.03201	Eval MAE Loss:0.15865
Epoch: 18/40 | Time: 0m 10s
	Train persuasion loss:0.00608	Train MAE Loss:0.06169
	Eval persuasion loss:0.03252	Eval MAE Loss:0.16141
Epoch: 19/40 | Time: 0m 9s
	Train persuasion loss:0.00613	Train MAE Loss:0.06150
	Eval persuasion loss:0.03065	Eval MAE Loss:0.15115
Epoch: 20/40 | Time: 0m 10s
	Train persuasion loss:0.00631	Train MAE Loss:0.06127
	Eval persuasion loss:0.03510	Eval MAE Loss:0.16739
Epoch: 21/40 | Time: 0m 10s
	Train persuasion loss:0.00615	Train MAE Loss:0.06224
	Eval persuasion loss:0.03346	Eval MAE Loss:0.16294
Epoch: 22/40 | Time: 0m 10s
	Train persuasion loss:0.00540	Train MAE Loss:0.05665
	Eval persuasion loss:0.03397	Eval MAE Loss:0.16502
Epoch: 23/40 | Time: 0m 11s
	Train persuasion loss:0.00523	Train MAE Loss:0.05629
	Eval persuasion loss:0.03452	Eval MAE Loss:0.16647
Epoch: 24/40 | Time: 0m 11s
	Train persuasion loss:0.00442	Train MAE Loss:0.05333
	Eval persuasion loss:0.03521	Eval MAE Loss:0.16889
Epoch: 25/40 | Time: 0m 10s
	Train persuasion loss:0.00513	Train MAE Loss:0.05721
	Eval persuasion loss:0.03579	Eval MAE Loss:0.17090
Epoch: 26/40 | Time: 0m 18s
	Train persuasion loss:0.00509	Train MAE Loss:0.05673
	Eval persuasion loss:0.03534	Eval MAE Loss:0.16944
Epoch: 27/40 | Time: 0m 30s
	Train persuasion loss:0.00521	Train MAE Loss:0.05852
	Eval persuasion loss:0.03498	Eval MAE Loss:0.16811
Epoch: 28/40 | Time: 0m 32s
	Train persuasion loss:0.00485	Train MAE Loss:0.05547
	Eval persuasion loss:0.03553	Eval MAE Loss:0.16982
Epoch: 29/40 | Time: 0m 10s
	Train persuasion loss:0.00505	Train MAE Loss:0.05517
	Eval persuasion loss:0.03647	Eval MAE Loss:0.17276
Epoch: 30/40 | Time: 0m 7s
	Train persuasion loss:0.00491	Train MAE Loss:0.05590
	Eval persuasion loss:0.03662	Eval MAE Loss:0.17263
Epoch: 31/40 | Time: 0m 7s
	Train persuasion loss:0.00475	Train MAE Loss:0.05298
	Eval persuasion loss:0.03657	Eval MAE Loss:0.17247
Epoch: 32/40 | Time: 0m 7s
	Train persuasion loss:0.00486	Train MAE Loss:0.05394
	Eval persuasion loss:0.03645	Eval MAE Loss:0.17208
Epoch: 33/40 | Time: 0m 7s
	Train persuasion loss:0.00499	Train MAE Loss:0.05597
	Eval persuasion loss:0.03622	Eval MAE Loss:0.17156
Epoch: 34/40 | Time: 0m 7s
	Train persuasion loss:0.00484	Train MAE Loss:0.05474
	Eval persuasion loss:0.03623	Eval MAE Loss:0.17174
Epoch: 35/40 | Time: 0m 7s
	Train persuasion loss:0.00535	Train MAE Loss:0.05723
	Eval persuasion loss:0.03634	Eval MAE Loss:0.17210
Epoch: 36/40 | Time: 0m 7s
	Train persuasion loss:0.00514	Train MAE Loss:0.05752
	Eval persuasion loss:0.03639	Eval MAE Loss:0.17229
Epoch: 37/40 | Time: 0m 7s
	Train persuasion loss:0.00502	Train MAE Loss:0.05516
	Eval persuasion loss:0.03630	Eval MAE Loss:0.17200
Epoch: 38/40 | Time: 0m 7s
	Train persuasion loss:0.00513	Train MAE Loss:0.05668
	Eval persuasion loss:0.03631	Eval MAE Loss:0.17211
Epoch: 39/40 | Time: 0m 7s
	Train persuasion loss:0.00568	Train MAE Loss:0.05932
	Eval persuasion loss:0.03625	Eval MAE Loss:0.17195
Epoch: 40/40 | Time: 0m 7s
	Train persuasion loss:0.00450	Train MAE Loss:0.05353
	Eval persuasion loss:0.03633	Eval MAE Loss:0.17214
FOLD 9
Let's use 10 GPUs!
Test persuasion loss:0.01829	Test MAE Loss:0.12306
MSE: 0.018
